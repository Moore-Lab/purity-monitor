{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bde8eeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import signal\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.signal import find_peaks\n",
    "#from natsort import natsorted\n",
    "import pandas as pd\n",
    "from scipy.signal import butter, lfilter, freqz, filtfilt\n",
    "from scipy.special import erfc\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#plt.style.use('../../style.mplstyle')\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import re, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "523916e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'../../purity-monitor/')\n",
    "sys.path.insert(0,'../WaveformAnalysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b4f5197",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Dataset as Dataset\n",
    "import StandMonitor as Monitor\n",
    "import PlotFunctions as Plt\n",
    "import Waveform as Waveform\n",
    "import SiPM as SiPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "461b70c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'SiPM' from '../../purity-monitor/SiPM.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(Dataset)\n",
    "importlib.reload(Monitor)\n",
    "importlib.reload(Plt)\n",
    "importlib.reload(SiPM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c07259a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sortfun(s):\n",
    "    offset = 1000 # file offset for directories witth \"rename\"\n",
    "    idx = float(s.split(\"_\")[-1][:-3])\n",
    "    if(\"overnight\" in s):\n",
    "        idx += offset\n",
    "    return idx\n",
    "\n",
    "def natsorted(l):\n",
    "    sl = sorted(l, key=sortfun)\n",
    "    return sl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b1740a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_filter(data, highfreq=1e5, lowfreq=100):\n",
    "\n",
    "    fs=1/(np.mean(np.diff(data.Ch[0].Time))/data.Ch[0].TScale)\n",
    "    nyq=0.5*fs\n",
    "\n",
    "    order=3\n",
    "    lowfreq=lowfreq\n",
    "    highfreq=highfreq\n",
    "    # type='band'\n",
    "\n",
    "    b, a = butter(order, [lowfreq/nyq, highfreq/nyq], btype='band', analog=False)\n",
    "\n",
    "    return b,a\n",
    "    \n",
    "def apply_filter(wf, b, a):\n",
    "    filtamp = filtfilt(b,a,wf)\n",
    "    return filtamp\n",
    "\n",
    "def func(x,base,V0,sigma,tau,mu):\n",
    "    return base + V0/2.0 * np.exp(0.5 * (sigma/tau)**2 - (x-mu)/tau) * erfc(1.0/np.sqrt(2.0) * (sigma/tau - (x-mu)/sigma))\n",
    "    \n",
    "def gauss_conv(x, mu=0, sigma=0.1):\n",
    "    x = x-mu\n",
    "    return np.exp(-np.square((x-mu)/sigma)/2)/(sigma*np.sqrt(2*np.pi))\n",
    "\n",
    "def apply_opt_filt(data, filtered_amp):\n",
    "    desire_x = np.arange(-500,500, data.Ch[0].Time[1]-data.Ch[0].Time[0])\n",
    "    desire_y = gauss_conv(desire_x)\n",
    "    desire_f = np.fft.fft(desire_y)\n",
    "\n",
    "    resp_x = np.arange(0,1000, data.Ch[0].Time[1]-data.Ch[0].Time[0])\n",
    "    resp_y = func(resp_x, 0, 1, 1.83, 46.93, 0)\n",
    "    resp_f = np.fft.fft(resp_y)\n",
    "\n",
    "    filter_f = desire_f/resp_f\n",
    "    filter_y = np.real(np.fft.ifft(filter_f))\n",
    "    \n",
    "    convol=np.convolve(filtered_amp, filter_y,'same')\n",
    "    #print('convol length', len(filtered_amp), len(filter_y), len(convol))\n",
    "        \n",
    "    return convol\n",
    "\n",
    "def search_waveform_for_peaks(vals, data, h=20, d=50):\n",
    "    peak_height = []\n",
    "    peak_pos = []\n",
    "    \n",
    "    peaks,pdict = find_peaks(vals,height=h,distance=d)\n",
    "    \n",
    "    ## sometimes there seems to be a problem with the time vector from teh dataset\n",
    "    ## so kludgily fix to make sure it always works\n",
    "    kludged_time_vec = np.linspace(data.Ch[0].Time[0],data.Ch[0].Time[-1],len(vals))\n",
    "    \n",
    "    #print(peaks)\n",
    "    \n",
    "    for peak, height in zip(peaks, pdict['peak_heights']):\n",
    "        \n",
    "        ## skip early peaks due to edge effect\n",
    "        if(peak <= d): \n",
    "            continue\n",
    "        \n",
    "        peak_height.append(height)\n",
    "        peak_pos.append(kludged_time_vec[peak])\n",
    "\n",
    "    return peak_height, peak_pos\n",
    "\n",
    "def get_ov_from_filename(f):\n",
    "    v = re.search('_\\d+\\.?\\d+V_',f)\n",
    "    if(v == None and \"20211119\" in f):\n",
    "        out_val = 31.0 ## first days data doesn't have OV in the name\n",
    "    elif(v == None):\n",
    "        print(\"Failed to find index for: \", f)\n",
    "        out_val = -9999.0\n",
    "    else:\n",
    "        out_val = float(v.group(0)[1:-2])\n",
    "    return out_val\n",
    "\n",
    "def get_index_from_filename(f):\n",
    "    v = re.search('_\\d+\\.h5',f)\n",
    "    if(v == None): print(\"Failed to find index for: \", f)\n",
    "    return int(v.group(0)[1:-3])\n",
    "\n",
    "def s_since_midnight(dt):\n",
    "    return (dt - dt.replace(hour=0, minute=0, second=0, microsecond=0)).total_seconds()\n",
    "\n",
    "def find_peaks_from_filelist(current_date, max_files = 1000, skip_files=1, make_plots=False, start_time=0, end_time=0):\n",
    "\n",
    "    peak_data = []\n",
    "    time_per_wf = 4.0\n",
    "    \n",
    "    total_time = (end_time - start_time).seconds\n",
    "        \n",
    "    data=SiPM.SiPM(Path='/project/david_moore/aj487/Data_WL110/LXe_Setup/TPC/%d/'%current_date,Selection='*DCR*.h5')\n",
    "    data.Ch=[Waveform.Waveform(ID=x, Pol=1) for x in range(1,3)]\n",
    "    print (\"Number of files for %d: \"%current_date, len(data.Files))\n",
    "\n",
    "    max_idx = int(np.min([max_files, len(data.Files)]))\n",
    "    print(\"Using %d files\"%max_idx)\n",
    "    \n",
    "    file_list = natsorted(data.Files)\n",
    "    time_list = np.linspace(datetime.timestamp(start_time), datetime.timestamp(end_time), len(file_list)+1)\n",
    "    \n",
    "    for i,File in enumerate(file_list[:max_idx:skip_files]):\n",
    "        \n",
    "        start_time_for_file = time_list[i]\n",
    "        end_time_for_file = time_list[i+1]\n",
    "        \n",
    "        if(i%10 == 0):\n",
    "            print(\"working on file: %d\"%i)\n",
    "        ##parse the filename for the OV\n",
    "        ov = get_ov_from_filename(File)\n",
    "        fidx = get_index_from_filename(File)\n",
    "\n",
    "        loaded_data=SiPM.SiPM(Path=File)\n",
    "        loaded_data.Ch = [Waveform.Waveform(ID=x, Pol=1) for x in range(1,3)]\n",
    "        try:\n",
    "            loaded_data.ImportDataFromHDF5(File, loaded_data.Ch)\n",
    "        except RuntimeError:\n",
    "            print(\"Failed to load file for %d index %d\"%(current_date, fidx))\n",
    "            continue\n",
    "        \n",
    "        b, a = make_filter(loaded_data)\n",
    "            \n",
    "        num_wfs = len(loaded_data.Ch[0].TimeStamp)\n",
    "        \n",
    "        time_list_for_file = np.linspace(start_time_for_file, end_time_for_file, num_wfs)\n",
    "        \n",
    "        for wfidx in range(num_wfs):\n",
    "            \n",
    "            if(False):\n",
    "                print(tstamp, loaded_data.Ch[0].TimeStamp[wfidx], loaded_data.Ch[0].TimeStamp[wfidx] + timedelta(hours=24*extra_days))\n",
    "            \n",
    "            tstamp = time_list_for_file[wfidx]\n",
    "            \n",
    "            orig_data = loaded_data.Ch[0].Amp[wfidx]\n",
    "            filt_data = apply_filter(orig_data, b, a)\n",
    "            opt_data = apply_opt_filt(loaded_data, filt_data)\n",
    "\n",
    "            peak_height, peak_pos = search_waveform_for_peaks(opt_data, loaded_data)\n",
    "        \n",
    "            if(make_plots):\n",
    "                plt.figure()\n",
    "                curr_time = tstamp+loaded_data.Ch[0].Time/loaded_data.Ch[0].TScale\n",
    "                plt.plot(curr_time,orig_data)\n",
    "                plt.plot(curr_time,filt_data)\n",
    "                plt.plot(curr_time,opt_data)\n",
    "            \n",
    "            for ph, pp in zip(peak_height, peak_pos):\n",
    "                peak_data.append([tstamp + pp/loaded_data.Ch[0].TScale, ph, ov, fidx])\n",
    "                \n",
    "                if(make_plots):\n",
    "                    plt.plot(tstamp + pp/loaded_data.Ch[0].TScale, ph, 'rx')\n",
    "\n",
    "            if(make_plots):\n",
    "                plt.show()\n",
    "            \n",
    "    return np.array(peak_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9f664a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20211201\n",
      "st= 2021-12-01 09:11:00\n",
      "et= 2021-12-01 23:59:00\n",
      "processed_data_20211201.npy\n",
      "Number of files for 20211201:  224\n",
      "Using 224 files\n",
      "working on file: 0\n",
      "working on file: 10\n",
      "working on file: 20\n",
      "working on file: 30\n",
      "working on file: 40\n",
      "working on file: 50\n",
      "working on file: 60\n",
      "working on file: 70\n",
      "working on file: 80\n",
      "working on file: 90\n",
      "working on file: 100\n",
      "working on file: 110\n",
      "working on file: 120\n",
      "working on file: 130\n",
      "working on file: 140\n",
      "working on file: 150\n",
      "working on file: 160\n",
      "working on file: 170\n",
      "working on file: 180\n",
      "working on file: 190\n",
      "working on file: 200\n",
      "working on file: 210\n",
      "working on file: 220\n",
      "(13198, 4)\n",
      "20211202\n",
      "st= 2021-12-02 09:09:00\n",
      "et= 2021-12-02 10:30:00\n",
      "processed_data_20211202.npy\n",
      "Number of files for 20211202:  16\n",
      "Using 16 files\n",
      "working on file: 0\n",
      "working on file: 10\n",
      "Failed to load file for 20211202 index 15\n",
      "(1636, 4)\n",
      "(0, 4)\n",
      "(14834, 4)\n"
     ]
    }
   ],
   "source": [
    "# date_list = [[20211119, [2021, 11, 19, 16, 29], [2021, 11, 21, 16, 24]],\n",
    "#              [20211122, [2021, 11, 22, 11, 6], [2021, 11, 23, 11, 5]],\n",
    "#              [20211123, [2021, 11, 23, 13, 44], [2021, 11, 24, 11, 3]],\n",
    "#              [20211124, [2021, 11, 24, 11, 18], [2021, 11, 25, 11, 9]],\n",
    "#              [20211125, [2021, 11, 25, 11, 23], [2021, 11, 26, 11, 1]],\n",
    "#              [20211129, [2021, 11, 29, 10, 56], [2021, 11, 29, 19, 22]]]\n",
    "\n",
    "date_list = [[20211201, [2021, 12, 1, 9, 11], [2021, 12, 1, 23, 59]],\n",
    "            [20211202, [2021, 12, 2, 9, 9], [2021, 12, 2, 10, 30]]]\n",
    "\n",
    "load_files = False\n",
    "save_files = True\n",
    "\n",
    "#%matplotlib notebook\n",
    "\n",
    "all_data = np.array([])\n",
    "\n",
    "for dv in date_list:\n",
    "\n",
    "    current_date = dv[0]\n",
    "    print(dv[0])\n",
    "\n",
    "    st = datetime(dv[1][0], dv[1][1], dv[1][2], hour=dv[1][3], minute=dv[1][4])\n",
    "    et = datetime(dv[2][0], dv[2][1], dv[2][2], hour=dv[2][3], minute=dv[2][4])\n",
    "    \n",
    "    print('st=',st)\n",
    "    print('et=',et)\n",
    "        \n",
    "    cf = \"processed_data_%d.npy\"%current_date\n",
    "    \n",
    "    print(cf)\n",
    "    \n",
    "    if(os.path.isfile(cf) and load_files):\n",
    "        pd = np.load(cf)\n",
    "    else:\n",
    "        pd = find_peaks_from_filelist(current_date, skip_files=1, start_time = st, end_time = et)\n",
    "        if(save_files):\n",
    "            np.save(cf, pd)\n",
    "    \n",
    "    print(np.shape(pd))\n",
    "    if(all_data.size > 0):\n",
    "        all_data = np.vstack((all_data, pd))\n",
    "    else:\n",
    "        all_data = pd\n",
    "    \n",
    "time_vec = (all_data[:,0]-np.min(all_data[:,0]))/(3600*24)\n",
    "new_data = all_data[ time_vec > 8, :]\n",
    "all_data = all_data[ time_vec < 8, :]\n",
    "\n",
    "print(np.shape(new_data))\n",
    "print(np.shape(all_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86eed52",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(8,6))\n",
    "time_vec = (all_data[:,0]-np.min(all_data[:,0]))/(3600*24)\n",
    "plt.plot( time_vec, all_data[:,1], 'k.', ms=1, rasterized=True )\n",
    "#print(3.52*(3600*24)+all_data[0,0])\n",
    "#plt.xlim((3.52,3.6))\n",
    "# plt.ylim((0,1000))\n",
    "plt.xlabel(\"Cumulative time since run start [days]\")\n",
    "plt.ylabel(\"Uncalibrated peak amplitude [mV]\")\n",
    "# fig.set_size_inches(6,4)\n",
    "plt.savefig(\"amp_vs_time_uncal.pdf\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77ae0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gauss_fun(x, A, mu, sig):\n",
    "    return A * np.exp( -(x-mu)**2/(2*sig**2) )\n",
    "\n",
    "def lin_fun(x, m, x1):\n",
    "    return m*(x-x1)\n",
    "\n",
    "def lin_fun_const(x, m):\n",
    "    return lin_fun(x,m,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb82e5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_hist(bc,hh, numsig=4, max_peaks=6):\n",
    "    \n",
    "    out_vals = []\n",
    "    \n",
    "    spe_loc = bc[np.argmax(hh)]\n",
    "    sig = spe_loc*0.05\n",
    "    fpts = np.logical_and( bc >= spe_loc - numsig*sig, bc <= spe_loc + numsig*sig)\n",
    "    \n",
    "    bestp, covp = curve_fit(gauss_fun, bc[fpts], hh[fpts], p0=[1, spe_loc, sig])\n",
    "    \n",
    "    out_vals.append([1, bestp[1], np.sqrt(covp[1,1])])\n",
    "    \n",
    "    xx = np.linspace( spe_loc - numsig*sig, spe_loc + numsig*sig, 100 )\n",
    "    plt.plot( xx, gauss_fun(xx, *bestp), 'r' )\n",
    "    \n",
    "    spe_loc = bestp[1]\n",
    "    sig = np.abs(bestp[2])\n",
    "    \n",
    "    for n in range(2,max_peaks):\n",
    "        \n",
    "        fpts = np.logical_and( bc >= n*spe_loc - numsig*sig, bc <= n*spe_loc + numsig*sig)\n",
    "        if(np.sum(fpts) == 0): \n",
    "            continue\n",
    "        \n",
    "        bestp, covp = curve_fit(gauss_fun, bc[fpts], hh[fpts], p0=[1, n*spe_loc, sig])\n",
    "        \n",
    "        out_vals.append([n, bestp[1], np.sqrt(covp[1,1])])\n",
    "        \n",
    "        xx = np.linspace( n*spe_loc - numsig*sig, n*spe_loc + numsig*sig, 100 )\n",
    "        plt.plot( xx, gauss_fun(xx, *bestp), 'r' )\n",
    "        \n",
    "        sig = np.abs(bestp[2])\n",
    "        \n",
    "        \n",
    "    return np.array(out_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef2b113",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibrate_data(all_data, max_peaks=6):\n",
    "\n",
    "    OV_list = np.unique(all_data[:,2])\n",
    "    print(OV_list)\n",
    "    \n",
    "    gain_vs_ov = np.zeros((len(OV_list),2))\n",
    "\n",
    "    for i, ov in enumerate(OV_list):\n",
    "        gpts = all_data[:, 2] == ov\n",
    "\n",
    "        hh, be = np.histogram(all_data[gpts, 1], bins=range(0,1000,1))\n",
    "        bc = be[:-1] + np.diff(be)/2\n",
    "\n",
    "        plt.figure()\n",
    "        plt.step(be[:-1], hh, where='post', color='k')\n",
    "        plt.gca().set_yscale('log')\n",
    "        yy = plt.ylim()\n",
    "\n",
    "        gain_list = fit_hist(bc,hh, max_peaks=max_peaks)\n",
    "        plt.ylim(yy)\n",
    "        plt.xlim(0,300)\n",
    "        \n",
    "        plt.title(\"Gain calibration, bias voltage = %.1f\"%ov)\n",
    "        plt.ylabel(\"Counts\")\n",
    "        plt.xlabel(\"Amplitude (mV)\")\n",
    "        plt.savefig(\"gain_calib_%.1f.pdf\"%ov)\n",
    "        \n",
    "        plt.figure()\n",
    "        plt.errorbar(gain_list[:,0], gain_list[:,1], yerr=gain_list[:,2], fmt='k.')\n",
    "        \n",
    "        linfitp, linfitcov = curve_fit(lin_fun_const, gain_list[:,0], gain_list[:,1], sigma=gain_list[:,2])\n",
    "        \n",
    "        xx = np.linspace(0, np.max(gain_list[:,0]), 100)\n",
    "        plt.plot(xx, lin_fun_const(xx,*linfitp), 'r', label=\"Gain = %.2f $\\pm$ %.2f mV/PE\"%(linfitp, np.sqrt(linfitcov)))\n",
    "        plt.legend()\n",
    "        \n",
    "        gain_vs_ov[i,0] = linfitp\n",
    "        gain_vs_ov[i,1] = np.sqrt(linfitcov)\n",
    "    \n",
    "    return gain_vs_ov, OV_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141f3db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gain_data_all, OV_list_all = calibrate_data(all_data)\n",
    "gain_data_new, OV_list_new = calibrate_data(new_data, max_peaks=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e21de07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_gain_data(fig, OV_list, gain_vs_ov, dc='k', lc='r'):\n",
    "\n",
    "    plt.figure(fig.number)\n",
    "    plt.errorbar(OV_list, gain_vs_ov[:,0], yerr=gain_vs_ov[:,1], fmt=dc+'.')\n",
    "\n",
    "    linfitp, linfitcov = curve_fit(lin_fun, OV_list, gain_vs_ov[:,0], sigma=gain_vs_ov[:,1])\n",
    "    linfiterr = np.sqrt(linfitcov[1,1])\n",
    "    xx = np.linspace(27, np.max(OV_list), 100 )\n",
    "    plt.plot( xx, lin_fun(xx, *linfitp), lc, label=r\"$V_{bd} = %.2f \\pm %.2f$\"%(linfitp[1], linfiterr))\n",
    "    plt.plot(xx, np.zeros_like(xx), 'k:')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9337b90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure()\n",
    "plot_gain_data(fig, OV_list_all, gain_data_all)\n",
    "# plot_gain_data(fig, OV_list_new, gain_data_new, dc='k', lc='c')\n",
    "plt.ylabel(\"Gain (mV/PE)\")\n",
    "plt.xlabel(\"Bias voltage (V)\")\n",
    "\n",
    "plt.legend()\n",
    "plt.savefig(\"gain_extrap.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d55d44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## now calibrate the rate plot in PE\n",
    "Vbd = 27.6\n",
    "\n",
    "timevec = (all_data[:,0]-np.min(all_data[:,0]))/(3600*24)\n",
    "amp_data_mV = all_data[:,1]\n",
    "amp_data_PE = np.zeros_like(amp_data_mV)\n",
    "\n",
    "for ov in OV_list_all:\n",
    "    gpts = all_data[:,2] == ov\n",
    "    curr_gain = gain_data_all[OV_list_all == ov,0][0]\n",
    "    amp_data_PE[gpts] = amp_data_mV[gpts]/curr_gain\n",
    "    \n",
    "fig=plt.figure()\n",
    "for ov in OV_list:\n",
    "    gpts = np.logical_and(amp_data_PE > 0.8, all_data[:,2] == ov)\n",
    "    p=plt.plot( time_vec[gpts], amp_data_PE[gpts], '.', ms=1, rasterized=True )\n",
    "    col=p[0].get_color()\n",
    "    plt.text(np.mean(time_vec[gpts]), 12, \"OV = %.1f V\"%(ov-Vbd), va='center', ha='center', color=col, weight='bold')\n",
    "plt.xlabel(\"Cumulative time since run start [days]\")\n",
    "plt.ylabel(\"Peak amplitude [PE]\")\n",
    "plt.ylim([0,13])\n",
    "fig.set_size_inches(10,4)\n",
    "plt.savefig(\"amp_vs_time_cal.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6778cc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure()\n",
    "\n",
    "## now a 2d histogram\n",
    "gpts = amp_data_PE > 0.8\n",
    "\n",
    "hh, xedges, yedges = np.histogram2d( time_vec[gpts], amp_data_PE[gpts], bins=(200,400) )\n",
    "\n",
    "tot_time = (433+228+226+225+222)*100*0.1\n",
    "nbins = 200\n",
    "time_per_bin = tot_time/nbins\n",
    "mm2 = 36\n",
    "conv_fac = 1/(time_per_bin * mm2)\n",
    "\n",
    "hh[hh == 0] = np.nan\n",
    "fig=plt.figure()\n",
    "plt.pcolormesh( xedges, yedges, hh.T * conv_fac, cmap='jet', rasterized=True)\n",
    "# plt.ylim(0,6.5)\n",
    "plt.colorbar(label=\"Rate [Hz/(mm * 0.025 PE)]\")\n",
    "plt.xlabel(\"Cumulative time since run start [days]\")\n",
    "plt.ylabel(\"Peak amplitude [PE]\")\n",
    "fig.set_size_inches(10,4)\n",
    "plt.savefig(\"amp_vs_time_histo.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db35875",
   "metadata": {},
   "outputs": [],
   "source": [
    "## now 1d rate plot\n",
    "\n",
    "gpts = amp_data_PE > 0.8\n",
    "hh, be = np.histogram( time_vec[gpts], bins=500 )\n",
    "bc = be[:-1] + np.diff(be)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59182ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "## now 1d rate plot\n",
    "\n",
    "fig=plt.figure()\n",
    "\n",
    "gpts = amp_data_PE > 0.8\n",
    "\n",
    "tot_time = (433+228+226+225+222)*100*0.1\n",
    "nbins = 10000\n",
    "time_per_bin = tot_time/nbins\n",
    "mm2 = 36\n",
    "conv_fac = 1/(time_per_bin * mm2)\n",
    "\n",
    "hh, be = np.histogram( time_vec[gpts], bins=nbins )\n",
    "bc = be[:-1] + np.diff(be)/2\n",
    "\n",
    "gpts = hh > 0\n",
    "gpts = np.logical_and( np.roll(hh, -1) > 0, gpts)\n",
    "gpts = np.logical_and( np.roll(hh, 1) > 0, gpts)\n",
    "\n",
    "plt.errorbar( bc[gpts], hh[gpts]*conv_fac, yerr=0*np.sqrt(hh[gpts])*conv_fac, fmt='k.', lw=0.5, ms=1, rasterized=True)\n",
    "\n",
    "nbins = 1000\n",
    "time_per_bin = tot_time/nbins\n",
    "mm2 = 36\n",
    "conv_fac = 1/(time_per_bin * mm2)\n",
    "\n",
    "gpts = amp_data_PE > 0.8\n",
    "hh, be = np.histogram( time_vec[gpts], bins=nbins )\n",
    "bc = be[:-1] + np.diff(be)/2\n",
    "\n",
    "gpts = hh > 0\n",
    "gpts = np.logical_and( np.roll(hh, -1) > 0, gpts)\n",
    "gpts = np.logical_and( np.roll(hh, 1) > 0, gpts)\n",
    "\n",
    "plt.errorbar( bc[gpts], hh[gpts]*conv_fac, yerr=np.sqrt(hh[gpts])*conv_fac, fmt='r.')\n",
    "\n",
    "for ov in OV_list_all:\n",
    "    gpts = np.logical_and(amp_data_PE > 0.8, all_data[:,2] == ov)\n",
    "\n",
    "    plt.text(np.mean(time_vec[gpts]), 0.8, \"OV = %.1f V\"%(ov-Vbd), va='center', ha='center', color='k', weight='bold')\n",
    "\n",
    "plt.xlabel(\"Cumulative time since run start [days]\")\n",
    "plt.ylabel(\"Dark rate [Hz/mm$^2$]\")\n",
    "plt.ylim([0,0.9])\n",
    "\n",
    "fig.set_size_inches(12,4)\n",
    "plt.savefig(\"rate_vs_time.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e20b8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
